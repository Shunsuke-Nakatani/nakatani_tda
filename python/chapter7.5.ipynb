{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.5 N-gramによる特徴量の再抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文字列を1文字ずつに分割してベクトル化。ベクトル化の手法はtf-idf。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# データセットを再ロードする\n",
    "df = pd.read_csv('./HttpParamsDataset/payload_train.csv')\n",
    "test_data = pd.read_csv('./HttpParamsDataset/payload_test.csv')\n",
    "\n",
    "train_rows = ((df.attack_type == 'norm') | (df.attack_type == 'sqli'))\n",
    "df = df[train_rows]\n",
    "\n",
    "test_train_rows = ((test_data.attack_type == 'norm') | (test_data.attack_type == 'sqli'))\n",
    "test_data = test_data[test_train_rows]\n",
    "\n",
    "df_y = df[['label']]\n",
    "test_y = test_data[['label']]\n",
    "\n",
    "df_x = df.iloc[:,:-1]\n",
    "test_x = test_data.iloc[:,:-1]\n",
    "\n",
    "X_all = pd.concat([df_x, test_x])\n",
    "y_all = pd.concat([df_y, test_y])\n",
    "\n",
    "rep = y_all.label.replace({\"norm\":0,\"anom\":1})\n",
    "y_all = y_all.assign(label=rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "抽出した特徴量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>payload</th>\n",
       "      <th>length</th>\n",
       "      <th>attack_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c/ caridad s/n</td>\n",
       "      <td>14</td>\n",
       "      <td>norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>campello, el</td>\n",
       "      <td>12</td>\n",
       "      <td>norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1442431887503330</td>\n",
       "      <td>16</td>\n",
       "      <td>norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nue37</td>\n",
       "      <td>5</td>\n",
       "      <td>norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tufts3@joll.rs</td>\n",
       "      <td>14</td>\n",
       "      <td>norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10176</th>\n",
       "      <td>1\") where 2367=2367;select (case when (4666=46...</td>\n",
       "      <td>113</td>\n",
       "      <td>sqli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10177</th>\n",
       "      <td>1') and updatexml(3393,concat(0x2e,0x7171706a7...</td>\n",
       "      <td>113</td>\n",
       "      <td>sqli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10178</th>\n",
       "      <td>1') as tqdg where 9355=9355;select (case when ...</td>\n",
       "      <td>136</td>\n",
       "      <td>sqli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10179</th>\n",
       "      <td>1') and extractvalue(7982,concat(0x5c,0x717170...</td>\n",
       "      <td>111</td>\n",
       "      <td>sqli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10180</th>\n",
       "      <td>1 rlike (select * from (select(sleep(5)))sgvo)...</td>\n",
       "      <td>53</td>\n",
       "      <td>sqli</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30156 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 payload  length attack_type\n",
       "0                                         c/ caridad s/n      14        norm\n",
       "1                                           campello, el      12        norm\n",
       "2                                       1442431887503330      16        norm\n",
       "3                                                  nue37       5        norm\n",
       "4                                         tufts3@joll.rs      14        norm\n",
       "...                                                  ...     ...         ...\n",
       "10176  1\") where 2367=2367;select (case when (4666=46...     113        sqli\n",
       "10177  1') and updatexml(3393,concat(0x2e,0x7171706a7...     113        sqli\n",
       "10178  1') as tqdg where 9355=9355;select (case when ...     136        sqli\n",
       "10179  1') and extractvalue(7982,concat(0x5c,0x717170...     111        sqli\n",
       "10180  1 rlike (select * from (select(sleep(5)))sgvo)...      53        sqli\n",
       "\n",
       "[30156 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ユニグラム(1文字ごとに分割)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X = X_all['payload']\n",
    "y = y_all\n",
    "\n",
    "# ベクトル化のためのオプションの設定、文字を対象にユニグラムを行う\n",
    "vec_opts = {\n",
    "    \"ngram_range\": (1, 1), \n",
    "    \"analyzer\": \"char\", \n",
    "    \"min_df\" : 0.1\n",
    "}\n",
    "\n",
    "# TfidfVectorizerの初期化\n",
    "v = TfidfVectorizer(**vec_opts)\n",
    "# ベクトル化の実行\n",
    "X = v.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "クエリ文字列中の文字の一覧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sinco\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([' ', '\"', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3',\n",
       "       '4', '5', '6', '7', '8', '9', '=', 'a', 'b', 'c', 'd', 'e', 'f',\n",
       "       'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u',\n",
       "       'v', 'w', 'x', 'y'], dtype='<U1')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 特徴に使用されている文字を出力\n",
    "features = v.get_feature_names()\n",
    "np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重みをつけられた文字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>\"</th>\n",
       "      <th>'</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>*</th>\n",
       "      <th>,</th>\n",
       "      <th>-</th>\n",
       "      <th>.</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>o</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.453262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209315</td>\n",
       "      <td>0.222629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.223881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211999</td>\n",
       "      <td>0.320803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.316555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.489108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.382917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.198388</td>\n",
       "      <td>0.422014</td>\n",
       "      <td>0.443910</td>\n",
       "      <td>0.259723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30151</th>\n",
       "      <td>0.427799</td>\n",
       "      <td>0.061067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132674</td>\n",
       "      <td>0.162360</td>\n",
       "      <td>0.062953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096652</td>\n",
       "      <td>0.117327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091180</td>\n",
       "      <td>0.290938</td>\n",
       "      <td>0.170019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30152</th>\n",
       "      <td>0.166014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.208435</td>\n",
       "      <td>0.267729</td>\n",
       "      <td>0.245725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.264680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031441</td>\n",
       "      <td>0.047577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032617</td>\n",
       "      <td>0.137235</td>\n",
       "      <td>0.040147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369485</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30153</th>\n",
       "      <td>0.468956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049065</td>\n",
       "      <td>0.126046</td>\n",
       "      <td>0.154249</td>\n",
       "      <td>0.059808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144375</td>\n",
       "      <td>0.245693</td>\n",
       "      <td>0.226136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30154</th>\n",
       "      <td>0.171542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.215375</td>\n",
       "      <td>0.276644</td>\n",
       "      <td>0.253907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.227911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.164692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031687</td>\n",
       "      <td>0.033703</td>\n",
       "      <td>0.177256</td>\n",
       "      <td>0.041484</td>\n",
       "      <td>0.188331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.254525</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30155</th>\n",
       "      <td>0.401641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359845</td>\n",
       "      <td>0.330270</td>\n",
       "      <td>0.128058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126775</td>\n",
       "      <td>0.095920</td>\n",
       "      <td>0.123651</td>\n",
       "      <td>0.394549</td>\n",
       "      <td>0.138340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124153</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30156 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        \"         '         (         )         *         ,  \\\n",
       "0      0.453262  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1      0.223881  0.000000  0.000000  0.000000  0.000000  0.000000  0.297448   \n",
       "2      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "30151  0.427799  0.061067  0.000000  0.132674  0.162360  0.062953  0.000000   \n",
       "30152  0.166014  0.000000  0.208435  0.267729  0.245725  0.000000  0.264680   \n",
       "30153  0.468956  0.000000  0.049065  0.126046  0.154249  0.059808  0.000000   \n",
       "30154  0.171542  0.000000  0.215375  0.276644  0.253907  0.000000  0.227911   \n",
       "30155  0.401641  0.000000  0.000000  0.359845  0.330270  0.128058  0.000000   \n",
       "\n",
       "              -         .         0  ...         o         p         r  \\\n",
       "0      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.209315   \n",
       "1      0.000000  0.000000  0.000000  ...  0.211999  0.320803  0.000000   \n",
       "2      0.000000  0.000000  0.316555  ...  0.000000  0.000000  0.000000   \n",
       "3      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "4      0.000000  0.382917  0.000000  ...  0.203400  0.000000  0.198388   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "30151  0.096652  0.117327  0.000000  ...  0.031161  0.000000  0.091180   \n",
       "30152  0.000000  0.000000  0.159385  ...  0.031441  0.047577  0.000000   \n",
       "30153  0.000000  0.055733  0.000000  ...  0.088813  0.000000  0.144375   \n",
       "30154  0.000000  0.000000  0.164692  ...  0.032488  0.000000  0.031687   \n",
       "30155  0.196609  0.000000  0.000000  ...  0.126775  0.095920  0.123651   \n",
       "\n",
       "              s         t         u         v         w         x         y  \n",
       "0      0.222629  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3      0.000000  0.000000  0.489108  0.000000  0.000000  0.000000  0.000000  \n",
       "4      0.422014  0.443910  0.259723  0.000000  0.000000  0.000000  0.000000  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "30151  0.290938  0.170019  0.000000  0.000000  0.100595  0.000000  0.056381  \n",
       "30152  0.032617  0.137235  0.040147  0.000000  0.000000  0.369485  0.000000  \n",
       "30153  0.245693  0.226136  0.000000  0.000000  0.095570  0.000000  0.000000  \n",
       "30154  0.033703  0.177256  0.041484  0.188331  0.000000  0.254525  0.000000  \n",
       "30155  0.394549  0.138340  0.000000  0.122486  0.000000  0.124153  0.000000  \n",
       "\n",
       "[30156 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X.toarray())\n",
    "df.columns = features\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ハイパーパラメータの探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-06 08:57:00,567]\u001b[0m A new study created in memory with name: no-name-cefc5929-8029-4c87-9812-be95d8a1cdb3\u001b[0m\n",
      "feature_fraction, val_score: 0.001620:  14%|#4        | 1/7 [00:03<00:21,  3.60s/it]\u001b[32m[I 2022-10-06 08:57:04,172]\u001b[0m Trial 0 finished with value: 0.0016196961321263488 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.0016196961321263488.\u001b[0m\n",
      "feature_fraction, val_score: 0.001369:  29%|##8       | 2/7 [00:07<00:18,  3.75s/it]\u001b[32m[I 2022-10-06 08:57:08,027]\u001b[0m Trial 1 finished with value: 0.001369233557887785 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.001369233557887785.\u001b[0m\n",
      "feature_fraction, val_score: 0.001369:  43%|####2     | 3/7 [00:10<00:14,  3.52s/it]\u001b[32m[I 2022-10-06 08:57:11,279]\u001b[0m Trial 2 finished with value: 0.0026813264855233285 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 0.001369233557887785.\u001b[0m\n",
      "feature_fraction, val_score: 0.001369:  57%|#####7    | 4/7 [00:14<00:10,  3.49s/it]\u001b[32m[I 2022-10-06 08:57:14,717]\u001b[0m Trial 3 finished with value: 0.001767617674357573 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.001369233557887785.\u001b[0m\n",
      "feature_fraction, val_score: 0.001341:  71%|#######1  | 5/7 [00:18<00:07,  3.81s/it]\u001b[32m[I 2022-10-06 08:57:19,098]\u001b[0m Trial 4 finished with value: 0.0013407664023609724 and parameters: {'feature_fraction': 0.5}. Best is trial 4 with value: 0.0013407664023609724.\u001b[0m\n",
      "feature_fraction, val_score: 0.001341:  86%|########5 | 6/7 [00:21<00:03,  3.68s/it]\u001b[32m[I 2022-10-06 08:57:22,519]\u001b[0m Trial 5 finished with value: 0.002341185530927046 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 4 with value: 0.0013407664023609724.\u001b[0m\n",
      "feature_fraction, val_score: 0.001341: 100%|##########| 7/7 [00:25<00:00,  3.59s/it]\u001b[32m[I 2022-10-06 08:57:25,917]\u001b[0m Trial 6 finished with value: 0.0020198510056756522 and parameters: {'feature_fraction': 0.8}. Best is trial 4 with value: 0.0013407664023609724.\u001b[0m\n",
      "feature_fraction, val_score: 0.001341: 100%|##########| 7/7 [00:25<00:00,  3.62s/it]\n",
      "num_leaves, val_score: 0.001282:   5%|5         | 1/20 [00:05<01:49,  5.77s/it]\u001b[32m[I 2022-10-06 08:57:31,690]\u001b[0m Trial 7 finished with value: 0.001281876799378727 and parameters: {'num_leaves': 103}. Best is trial 7 with value: 0.001281876799378727.\u001b[0m\n",
      "num_leaves, val_score: 0.001282:  10%|#         | 2/20 [00:12<01:50,  6.16s/it]\u001b[32m[I 2022-10-06 08:57:38,125]\u001b[0m Trial 8 finished with value: 0.0013185014501888492 and parameters: {'num_leaves': 125}. Best is trial 7 with value: 0.001281876799378727.\u001b[0m\n",
      "num_leaves, val_score: 0.001282:  15%|#5        | 3/20 [00:18<01:42,  6.06s/it]\u001b[32m[I 2022-10-06 08:57:44,058]\u001b[0m Trial 9 finished with value: 0.0012836119112165814 and parameters: {'num_leaves': 102}. Best is trial 7 with value: 0.001281876799378727.\u001b[0m\n",
      "num_leaves, val_score: 0.001282:  20%|##        | 4/20 [00:24<01:39,  6.21s/it]\u001b[32m[I 2022-10-06 08:57:50,511]\u001b[0m Trial 10 finished with value: 0.0012825459168002576 and parameters: {'num_leaves': 146}. Best is trial 7 with value: 0.001281876799378727.\u001b[0m\n",
      "num_leaves, val_score: 0.001282:  25%|##5       | 5/20 [00:29<01:27,  5.85s/it]\u001b[32m[I 2022-10-06 08:57:55,724]\u001b[0m Trial 11 finished with value: 0.0013077594545525227 and parameters: {'num_leaves': 67}. Best is trial 7 with value: 0.001281876799378727.\u001b[0m\n",
      "num_leaves, val_score: 0.001282:  30%|###       | 6/20 [00:35<01:22,  5.91s/it]\u001b[32m[I 2022-10-06 08:58:01,734]\u001b[0m Trial 12 finished with value: 0.001341174763729008 and parameters: {'num_leaves': 98}. Best is trial 7 with value: 0.001281876799378727.\u001b[0m\n",
      "num_leaves, val_score: 0.001282:  35%|###5      | 7/20 [00:39<01:08,  5.28s/it]\u001b[32m[I 2022-10-06 08:58:05,718]\u001b[0m Trial 13 finished with value: 0.0014545504888080387 and parameters: {'num_leaves': 5}. Best is trial 7 with value: 0.001281876799378727.\u001b[0m\n",
      "num_leaves, val_score: 0.001282:  40%|####      | 8/20 [00:46<01:10,  5.87s/it]\u001b[32m[I 2022-10-06 08:58:12,859]\u001b[0m Trial 14 finished with value: 0.001337590128399854 and parameters: {'num_leaves': 172}. Best is trial 7 with value: 0.001281876799378727.\u001b[0m\n",
      "num_leaves, val_score: 0.001282:  45%|####5     | 9/20 [00:53<01:05,  6.00s/it]\u001b[32m[I 2022-10-06 08:58:19,133]\u001b[0m Trial 15 finished with value: 0.001319356198128071 and parameters: {'num_leaves': 126}. Best is trial 7 with value: 0.001281876799378727.\u001b[0m\n",
      "num_leaves, val_score: 0.001282:  50%|#####     | 10/20 [01:01<01:06,  6.63s/it]\u001b[32m[I 2022-10-06 08:58:27,174]\u001b[0m Trial 16 finished with value: 0.0012945868448993281 and parameters: {'num_leaves': 216}. Best is trial 7 with value: 0.001281876799378727.\u001b[0m\n",
      "num_leaves, val_score: 0.001282:  55%|#####5    | 11/20 [01:05<00:53,  5.89s/it]\u001b[32m[I 2022-10-06 08:58:31,392]\u001b[0m Trial 17 finished with value: 0.0013367075239648207 and parameters: {'num_leaves': 34}. Best is trial 7 with value: 0.001281876799378727.\u001b[0m\n",
      "num_leaves, val_score: 0.001282:  60%|######    | 12/20 [01:12<00:50,  6.25s/it]\u001b[32m[I 2022-10-06 08:58:38,473]\u001b[0m Trial 18 finished with value: 0.0013201901094799515 and parameters: {'num_leaves': 173}. Best is trial 7 with value: 0.001281876799378727.\u001b[0m\n",
      "num_leaves, val_score: 0.001282:  65%|######5   | 13/20 [01:20<00:46,  6.69s/it]\u001b[32m[I 2022-10-06 08:58:46,154]\u001b[0m Trial 19 finished with value: 0.0013307473516498607 and parameters: {'num_leaves': 170}. Best is trial 7 with value: 0.001281876799378727.\u001b[0m\n",
      "num_leaves, val_score: 0.001282:  70%|#######   | 14/20 [01:28<00:43,  7.21s/it]\u001b[32m[I 2022-10-06 08:58:54,564]\u001b[0m Trial 20 finished with value: 0.0012865195542554062 and parameters: {'num_leaves': 249}. Best is trial 7 with value: 0.001281876799378727.\u001b[0m\n",
      "num_leaves, val_score: 0.001282:  75%|#######5  | 15/20 [01:33<00:33,  6.64s/it]\u001b[32m[I 2022-10-06 08:58:59,891]\u001b[0m Trial 21 finished with value: 0.0013082999462678596 and parameters: {'num_leaves': 86}. Best is trial 7 with value: 0.001281876799378727.\u001b[0m\n",
      "num_leaves, val_score: 0.001282:  80%|########  | 16/20 [01:40<00:26,  6.59s/it]\u001b[32m[I 2022-10-06 08:59:06,369]\u001b[0m Trial 22 finished with value: 0.0012966397962889764 and parameters: {'num_leaves': 149}. Best is trial 7 with value: 0.001281876799378727.\u001b[0m\n",
      "num_leaves, val_score: 0.001282:  85%|########5 | 17/20 [01:45<00:17,  5.98s/it]\u001b[32m[I 2022-10-06 08:59:10,942]\u001b[0m Trial 23 finished with value: 0.001334255595278892 and parameters: {'num_leaves': 52}. Best is trial 7 with value: 0.001281876799378727.\u001b[0m\n",
      "num_leaves, val_score: 0.001271:  90%|######### | 18/20 [01:52<00:12,  6.45s/it]\u001b[32m[I 2022-10-06 08:59:18,460]\u001b[0m Trial 24 finished with value: 0.001271139166599938 and parameters: {'num_leaves': 197}. Best is trial 24 with value: 0.001271139166599938.\u001b[0m\n",
      "num_leaves, val_score: 0.001271:  95%|#########5| 19/20 [02:00<00:06,  6.93s/it]\u001b[32m[I 2022-10-06 08:59:26,519]\u001b[0m Trial 25 finished with value: 0.0013166378250545315 and parameters: {'num_leaves': 213}. Best is trial 24 with value: 0.001271139166599938.\u001b[0m\n",
      "num_leaves, val_score: 0.001271: 100%|##########| 20/20 [02:08<00:00,  7.35s/it]\u001b[32m[I 2022-10-06 08:59:34,841]\u001b[0m Trial 26 finished with value: 0.001292969247861832 and parameters: {'num_leaves': 204}. Best is trial 24 with value: 0.001271139166599938.\u001b[0m\n",
      "num_leaves, val_score: 0.001271: 100%|##########| 20/20 [02:08<00:00,  6.45s/it]\n",
      "bagging, val_score: 0.001210:  10%|#         | 1/10 [00:07<01:04,  7.11s/it]\u001b[32m[I 2022-10-06 08:59:41,959]\u001b[0m Trial 27 finished with value: 0.001210159957745233 and parameters: {'bagging_fraction': 0.5389360795705654, 'bagging_freq': 2}. Best is trial 27 with value: 0.001210159957745233.\u001b[0m\n",
      "bagging, val_score: 0.001210:  20%|##        | 2/10 [00:15<01:01,  7.72s/it]\u001b[32m[I 2022-10-06 08:59:50,105]\u001b[0m Trial 28 finished with value: 0.001297740481286795 and parameters: {'bagging_fraction': 0.9800930161018813, 'bagging_freq': 5}. Best is trial 27 with value: 0.001210159957745233.\u001b[0m\n",
      "bagging, val_score: 0.001210:  30%|###       | 3/10 [00:22<00:52,  7.44s/it]\u001b[32m[I 2022-10-06 08:59:57,210]\u001b[0m Trial 29 finished with value: 0.001266461815641186 and parameters: {'bagging_fraction': 0.6489061688146325, 'bagging_freq': 6}. Best is trial 27 with value: 0.001210159957745233.\u001b[0m\n",
      "bagging, val_score: 0.001165:  40%|####      | 4/10 [00:29<00:45,  7.51s/it]\u001b[32m[I 2022-10-06 09:00:04,835]\u001b[0m Trial 30 finished with value: 0.0011648145867418757 and parameters: {'bagging_fraction': 0.649607785851483, 'bagging_freq': 1}. Best is trial 30 with value: 0.0011648145867418757.\u001b[0m\n",
      "bagging, val_score: 0.001165:  50%|#####     | 5/10 [00:37<00:38,  7.66s/it]\u001b[32m[I 2022-10-06 09:00:12,748]\u001b[0m Trial 31 finished with value: 0.001349763986531399 and parameters: {'bagging_fraction': 0.9035099651851339, 'bagging_freq': 5}. Best is trial 30 with value: 0.0011648145867418757.\u001b[0m\n",
      "bagging, val_score: 0.001165:  60%|######    | 6/10 [00:45<00:30,  7.54s/it]\u001b[32m[I 2022-10-06 09:00:20,072]\u001b[0m Trial 32 finished with value: 0.0012661675692251895 and parameters: {'bagging_fraction': 0.7134288780726943, 'bagging_freq': 4}. Best is trial 30 with value: 0.0011648145867418757.\u001b[0m\n",
      "bagging, val_score: 0.001165:  70%|#######   | 7/10 [00:53<00:22,  7.66s/it]\u001b[32m[I 2022-10-06 09:00:27,956]\u001b[0m Trial 33 finished with value: 0.00131094572007773 and parameters: {'bagging_fraction': 0.8651452852335704, 'bagging_freq': 5}. Best is trial 30 with value: 0.0011648145867418757.\u001b[0m\n",
      "bagging, val_score: 0.001165:  80%|########  | 8/10 [01:00<00:15,  7.62s/it]\u001b[32m[I 2022-10-06 09:00:35,495]\u001b[0m Trial 34 finished with value: 0.0012876627473968386 and parameters: {'bagging_fraction': 0.5380465716126583, 'bagging_freq': 1}. Best is trial 30 with value: 0.0011648145867418757.\u001b[0m\n",
      "bagging, val_score: 0.001091:  90%|######### | 9/10 [01:07<00:07,  7.41s/it]\u001b[32m[I 2022-10-06 09:00:42,446]\u001b[0m Trial 35 finished with value: 0.001090808437849666 and parameters: {'bagging_fraction': 0.5531809737673176, 'bagging_freq': 6}. Best is trial 35 with value: 0.001090808437849666.\u001b[0m\n",
      "bagging, val_score: 0.001091: 100%|##########| 10/10 [01:15<00:00,  7.68s/it]\u001b[32m[I 2022-10-06 09:00:50,738]\u001b[0m Trial 36 finished with value: 0.0013008790625650976 and parameters: {'bagging_fraction': 0.8868687847806946, 'bagging_freq': 1}. Best is trial 35 with value: 0.001090808437849666.\u001b[0m\n",
      "bagging, val_score: 0.001091: 100%|##########| 10/10 [01:15<00:00,  7.59s/it]\n",
      "feature_fraction_stage2, val_score: 0.001091:  17%|#6        | 1/6 [00:07<00:37,  7.42s/it]\u001b[32m[I 2022-10-06 09:00:58,164]\u001b[0m Trial 37 finished with value: 0.001090808437849666 and parameters: {'feature_fraction': 0.516}. Best is trial 37 with value: 0.001090808437849666.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.001072:  33%|###3      | 2/6 [00:14<00:27,  6.97s/it]\u001b[32m[I 2022-10-06 09:01:04,815]\u001b[0m Trial 38 finished with value: 0.00107188593489586 and parameters: {'feature_fraction': 0.45199999999999996}. Best is trial 38 with value: 0.00107188593489586.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.001072:  50%|#####     | 3/6 [00:21<00:21,  7.02s/it]\u001b[32m[I 2022-10-06 09:01:11,889]\u001b[0m Trial 39 finished with value: 0.0012138266043833072 and parameters: {'feature_fraction': 0.5479999999999999}. Best is trial 38 with value: 0.00107188593489586.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.001072:  67%|######6   | 4/6 [00:28<00:13,  7.00s/it]\u001b[32m[I 2022-10-06 09:01:18,851]\u001b[0m Trial 40 finished with value: 0.0011872475745691772 and parameters: {'feature_fraction': 0.484}. Best is trial 38 with value: 0.00107188593489586.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.001072:  83%|########3 | 5/6 [00:35<00:07,  7.01s/it]\u001b[32m[I 2022-10-06 09:01:25,894]\u001b[0m Trial 41 finished with value: 0.0013406655915775502 and parameters: {'feature_fraction': 0.58}. Best is trial 38 with value: 0.00107188593489586.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.001072: 100%|##########| 6/6 [00:41<00:00,  6.87s/it]\u001b[32m[I 2022-10-06 09:01:32,490]\u001b[0m Trial 42 finished with value: 0.001075442649437507 and parameters: {'feature_fraction': 0.42}. Best is trial 38 with value: 0.00107188593489586.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.001072: 100%|##########| 6/6 [00:41<00:00,  6.96s/it]\n",
      "regularization_factors, val_score: 0.001072:   5%|5         | 1/20 [00:03<01:02,  3.28s/it]\u001b[32m[I 2022-10-06 09:01:35,773]\u001b[0m Trial 43 finished with value: 0.0011237896680599147 and parameters: {'lambda_l1': 0.010391062414954876, 'lambda_l2': 8.165888352202155e-05}. Best is trial 43 with value: 0.0011237896680599147.\u001b[0m\n",
      "regularization_factors, val_score: 0.001072:  10%|#         | 2/20 [00:09<01:25,  4.77s/it]\u001b[32m[I 2022-10-06 09:01:41,593]\u001b[0m Trial 44 finished with value: 0.0011228007093758599 and parameters: {'lambda_l1': 2.74883197203785e-05, 'lambda_l2': 0.14129660016898346}. Best is trial 44 with value: 0.0011228007093758599.\u001b[0m\n",
      "regularization_factors, val_score: 0.001072:  15%|#5        | 3/20 [00:11<01:02,  3.69s/it]\u001b[32m[I 2022-10-06 09:01:43,994]\u001b[0m Trial 45 finished with value: 0.0026475272496904716 and parameters: {'lambda_l1': 3.346446581770265, 'lambda_l2': 0.0004924984730119698}. Best is trial 44 with value: 0.0011228007093758599.\u001b[0m\n",
      "regularization_factors, val_score: 0.001039:  20%|##        | 4/20 [00:16<01:07,  4.21s/it]\u001b[32m[I 2022-10-06 09:01:48,999]\u001b[0m Trial 46 finished with value: 0.0010391085463860865 and parameters: {'lambda_l1': 1.8346129870936297e-06, 'lambda_l2': 3.168444643912967e-08}. Best is trial 46 with value: 0.0010391085463860865.\u001b[0m\n",
      "regularization_factors, val_score: 0.001027:  25%|##5       | 5/20 [00:21<01:06,  4.40s/it]\u001b[32m[I 2022-10-06 09:01:53,747]\u001b[0m Trial 47 finished with value: 0.0010269829275741352 and parameters: {'lambda_l1': 1.1625835679656852e-05, 'lambda_l2': 3.625348457464948e-08}. Best is trial 47 with value: 0.0010269829275741352.\u001b[0m\n",
      "regularization_factors, val_score: 0.001027:  30%|###       | 6/20 [00:24<00:57,  4.09s/it]\u001b[32m[I 2022-10-06 09:01:57,237]\u001b[0m Trial 48 finished with value: 0.0011551011653629267 and parameters: {'lambda_l1': 0.023827022030696306, 'lambda_l2': 0.000774221706495628}. Best is trial 47 with value: 0.0010269829275741352.\u001b[0m\n",
      "regularization_factors, val_score: 0.001027:  35%|###5      | 7/20 [00:30<01:01,  4.70s/it]\u001b[32m[I 2022-10-06 09:02:03,188]\u001b[0m Trial 49 finished with value: 0.0011796177243611357 and parameters: {'lambda_l1': 2.999545350851877e-08, 'lambda_l2': 0.0820240256600164}. Best is trial 47 with value: 0.0010269829275741352.\u001b[0m\n",
      "regularization_factors, val_score: 0.001027:  40%|####      | 8/20 [00:34<00:54,  4.56s/it]\u001b[32m[I 2022-10-06 09:02:07,452]\u001b[0m Trial 50 finished with value: 0.001129028426904446 and parameters: {'lambda_l1': 2.817422553746014e-07, 'lambda_l2': 0.00023143965579382525}. Best is trial 47 with value: 0.0010269829275741352.\u001b[0m\n",
      "regularization_factors, val_score: 0.001027:  45%|####5     | 9/20 [00:37<00:42,  3.87s/it]\u001b[32m[I 2022-10-06 09:02:09,805]\u001b[0m Trial 51 finished with value: 0.005475382475631278 and parameters: {'lambda_l1': 9.374985165412033, 'lambda_l2': 3.1509225319895923e-06}. Best is trial 47 with value: 0.0010269829275741352.\u001b[0m\n",
      "regularization_factors, val_score: 0.001027:  50%|#####     | 10/20 [00:43<00:44,  4.44s/it]\u001b[32m[I 2022-10-06 09:02:15,524]\u001b[0m Trial 52 finished with value: 0.0011450780047471514 and parameters: {'lambda_l1': 2.0449672348749346e-07, 'lambda_l2': 0.12051588244890869}. Best is trial 47 with value: 0.0010269829275741352.\u001b[0m\n",
      "regularization_factors, val_score: 0.001027:  55%|#####5    | 11/20 [00:47<00:39,  4.36s/it]\u001b[32m[I 2022-10-06 09:02:19,689]\u001b[0m Trial 53 finished with value: 0.0011137524838746842 and parameters: {'lambda_l1': 0.0002211447287447743, 'lambda_l2': 2.8810166224861507e-08}. Best is trial 47 with value: 0.0010269829275741352.\u001b[0m\n",
      "regularization_factors, val_score: 0.001027:  60%|######    | 12/20 [00:51<00:35,  4.48s/it]\u001b[32m[I 2022-10-06 09:02:24,445]\u001b[0m Trial 54 finished with value: 0.0010778157330965947 and parameters: {'lambda_l1': 6.724044961150874e-06, 'lambda_l2': 1.3965987049716261e-08}. Best is trial 47 with value: 0.0010269829275741352.\u001b[0m\n",
      "regularization_factors, val_score: 0.001027:  65%|######5   | 13/20 [00:56<00:31,  4.50s/it]\u001b[32m[I 2022-10-06 09:02:29,000]\u001b[0m Trial 55 finished with value: 0.001084070936831691 and parameters: {'lambda_l1': 1.0529581390547611e-05, 'lambda_l2': 7.413538594715292e-07}. Best is trial 47 with value: 0.0010269829275741352.\u001b[0m\n",
      "regularization_factors, val_score: 0.001027:  70%|#######   | 14/20 [01:01<00:27,  4.64s/it]\u001b[32m[I 2022-10-06 09:02:33,956]\u001b[0m Trial 56 finished with value: 0.0010432674806378646 and parameters: {'lambda_l1': 7.799588782231282e-07, 'lambda_l2': 4.147339414707935e-07}. Best is trial 47 with value: 0.0010269829275741352.\u001b[0m\n",
      "regularization_factors, val_score: 0.001027:  75%|#######5  | 15/20 [01:09<00:28,  5.60s/it]\u001b[32m[I 2022-10-06 09:02:41,789]\u001b[0m Trial 57 finished with value: 0.0011372553354276444 and parameters: {'lambda_l1': 0.0015997053179434327, 'lambda_l2': 4.902532497180068}. Best is trial 47 with value: 0.0010269829275741352.\u001b[0m\n",
      "regularization_factors, val_score: 0.001027:  80%|########  | 16/20 [01:13<00:20,  5.22s/it]\u001b[32m[I 2022-10-06 09:02:46,112]\u001b[0m Trial 58 finished with value: 0.0010597656719326454 and parameters: {'lambda_l1': 0.0001228270423773623, 'lambda_l2': 1.316820214546477e-05}. Best is trial 47 with value: 0.0010269829275741352.\u001b[0m\n",
      "regularization_factors, val_score: 0.001027:  85%|########5 | 17/20 [01:19<00:15,  5.27s/it]\u001b[32m[I 2022-10-06 09:02:51,503]\u001b[0m Trial 59 finished with value: 0.0010872333287662587 and parameters: {'lambda_l1': 1.659909948574365e-08, 'lambda_l2': 4.936412672556111e-08}. Best is trial 47 with value: 0.0010269829275741352.\u001b[0m\n",
      "regularization_factors, val_score: 0.001026:  90%|######### | 18/20 [01:24<00:10,  5.19s/it]\u001b[32m[I 2022-10-06 09:02:56,500]\u001b[0m Trial 60 finished with value: 0.001026311642638085 and parameters: {'lambda_l1': 2.032882278931507e-06, 'lambda_l2': 1.61664463391204e-07}. Best is trial 60 with value: 0.001026311642638085.\u001b[0m\n",
      "regularization_factors, val_score: 0.001026:  95%|#########5| 19/20 [01:27<00:04,  4.58s/it]\u001b[32m[I 2022-10-06 09:02:59,654]\u001b[0m Trial 61 finished with value: 0.001086002360045825 and parameters: {'lambda_l1': 0.13167249386143332, 'lambda_l2': 4.0687454808916776e-07}. Best is trial 60 with value: 0.001026311642638085.\u001b[0m\n",
      "regularization_factors, val_score: 0.001026: 100%|##########| 20/20 [01:31<00:00,  4.58s/it]\u001b[32m[I 2022-10-06 09:03:04,249]\u001b[0m Trial 62 finished with value: 0.0011680000861222072 and parameters: {'lambda_l1': 0.0011968440517077122, 'lambda_l2': 0.005997167555893567}. Best is trial 60 with value: 0.001026311642638085.\u001b[0m\n",
      "regularization_factors, val_score: 0.001026: 100%|##########| 20/20 [01:31<00:00,  4.59s/it]\n",
      "min_data_in_leaf, val_score: 0.001026:  20%|##        | 1/5 [00:04<00:17,  4.42s/it]\u001b[32m[I 2022-10-06 09:03:08,671]\u001b[0m Trial 63 finished with value: 0.0010596214552482132 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.0010596214552482132.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.001026:  40%|####      | 2/5 [00:09<00:15,  5.01s/it]\u001b[32m[I 2022-10-06 09:03:14,087]\u001b[0m Trial 64 finished with value: 0.001101733361600218 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.0010596214552482132.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.001023:  60%|######    | 3/5 [00:14<00:09,  4.94s/it]\u001b[32m[I 2022-10-06 09:03:18,951]\u001b[0m Trial 65 finished with value: 0.0010225229945314174 and parameters: {'min_child_samples': 25}. Best is trial 65 with value: 0.0010225229945314174.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.001023:  80%|########  | 4/5 [00:19<00:05,  5.02s/it]\u001b[32m[I 2022-10-06 09:03:24,093]\u001b[0m Trial 66 finished with value: 0.0012025355270856056 and parameters: {'min_child_samples': 5}. Best is trial 65 with value: 0.0010225229945314174.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.001023: 100%|##########| 5/5 [00:24<00:00,  4.86s/it]\u001b[32m[I 2022-10-06 09:03:28,672]\u001b[0m Trial 67 finished with value: 0.0011596324094071632 and parameters: {'min_child_samples': 50}. Best is trial 65 with value: 0.0010225229945314174.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.001023: 100%|##########| 5/5 [00:24<00:00,  4.88s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna.integration.lightgbm as olgb\n",
    "import optuna\n",
    "\n",
    "# データセットを訓練用とテスト用に分割\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X, y, test_size=0.2, shuffle=True, random_state=101)\n",
    "\n",
    "# LightGBM用のデータセットに変換\n",
    "train = olgb.Dataset(X_train, y_train)\n",
    "\n",
    "# パラメータの設定\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"verbosity\": -1,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "}\n",
    "\n",
    "# 交差検証を使用したハイパーパラメータの探索\n",
    "tuner = olgb.LightGBMTunerCV(params, train)\n",
    "\n",
    "# ハイパーパラメータ探索の実行\n",
    "tuner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ベストスコアの表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9989774770054686\n",
      "Best params: {'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'feature_pre_filter': False, 'lambda_l1': 2.032882278931507e-06, 'lambda_l2': 1.61664463391204e-07, 'num_leaves': 197, 'feature_fraction': 0.45199999999999996, 'bagging_fraction': 0.5531809737673176, 'bagging_freq': 6, 'min_child_samples': 25}\n",
      "  Params: \n",
      "    objective: binary\n",
      "    metric: binary_logloss\n",
      "    verbosity: -1\n",
      "    boosting_type: gbdt\n",
      "    feature_pre_filter: False\n",
      "    lambda_l1: 2.032882278931507e-06\n",
      "    lambda_l2: 1.61664463391204e-07\n",
      "    num_leaves: 197\n",
      "    feature_fraction: 0.45199999999999996\n",
      "    bagging_fraction: 0.5531809737673176\n",
      "    bagging_freq: 6\n",
      "    min_child_samples: 25\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score:\", 1 - tuner.best_score)\n",
    "best_params = tuner.best_params\n",
    "print(\"Best params:\", best_params)\n",
    "print(\"  Params: \")\n",
    "for key, value in best_params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練・実行し、正答率を表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sinco\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.96684 %\n",
      "[[3847    0]\n",
      " [   2 2183]]\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 訓練データとテストデータを設定\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test)\n",
    "\n",
    "# ハイパーパラメータ探索で特定した値を設定\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'lambda_l1': best_params['lambda_l1'],\n",
    "    'lambda_l2': best_params['lambda_l2'],\n",
    "    'num_leaves': best_params['num_leaves'],\n",
    "    'feature_fraction': best_params['feature_fraction'],\n",
    "    'bagging_fraction': best_params['bagging_fraction'],\n",
    "    'bagging_freq': best_params['bagging_freq'],\n",
    "    'min_child_samples': best_params['min_child_samples']\n",
    "}\n",
    "\n",
    "# 訓練の実施\n",
    "gbm = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=100,\n",
    "    verbose_eval=0,\n",
    ")\n",
    "\n",
    "# テスト用データを使って予測する\n",
    "preds = gbm.predict(X_test)\n",
    "# 戻り値は確率になっているので四捨五入する\n",
    "pred_labels = np.rint(preds)\n",
    "# 正解率と混同行列の出力\n",
    "print(\"Accuracy: {:.5f} %\".format(100 * accuracy_score(y_test, pred_labels)))\n",
    "print(confusion_matrix(y_test, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6032x43 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 85680 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cfa6768c21de3901852213cc8ace0c76992ac9ee5c616b45c25a642d8902200e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
